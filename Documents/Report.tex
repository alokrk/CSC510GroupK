% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate-05-2015}
\usepackage{hyperref}

\begin{document}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}






%
% --- Author Metadata here ---

%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{User Customized Temporal Content Recommendations for StackOverflow}
%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as
%\textit{Author's Guide to Preparing ACM SIG Proceedings Using
%\LaTeX$2_\epsilon$\ and BibTeX} at
%\texttt{www.acm.org/eaddress.htm}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{4} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
	Alok Kucheria\\
       \affaddr{Department of Computer Science}\\
       \affaddr{NC State University}\\
       %\affaddr{Raleigh 27606}\\
       \email{akucher@ncsu.edu}
% 2nd. author
\alignauthor
Karthik Sheshadri\\
       \affaddr{Department of Computer Science}\\
       \affaddr{NC State University}\\
       %\affaddr{Raleigh 27606}\\
       \email{kshesha@ncsu.edu}
\and
% 3rd. author
\alignauthor
Nandini Rangaswamy\\
       \affaddr{Department of Computer Science}\\
       \affaddr{NC State University}\\
       %\affaddr{Raleigh 27606}\\
       \email{nrangas@ncsu.edu}
%\and  % use '\and' if you need 'another row' of author names
%% 4th. author
\alignauthor
Raman Preet Singh\\
       \affaddr{Department of Computer Science}\\
       \affaddr{NC State University}\\
       %\affaddr{Raleigh 27606}\\
       \email{rpsingh2@ncsu.edu}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
\textbf{We present a survey of 150+ StackOveflow users, which motivates the use of StackOverflow as a corpus for delivering temporally relevant, personalized content recommendations to specific users based on their stated interests. We demonstrate, through our survey, the inability of the existing StackOverflow newsletter to provide this function. We propose a user adaptive recommendation system to address the problem, and present it in context of related work. Finally, we present a brief statement of our start up exercise with a simulated system output.}
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%





%
% End generated code
%

%
%  Use this command to print the description
%


% We no longer use \terms command
%\terms{Theory}

\keywords{customization, stack overflow, recommendation, ranking,filtering, temporal data}
\label{key}

\section{Introduction}
\label{intro}
\vspace{0.2cm}
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{ChartGo}
\caption{The case for our proposed system, from a survey of 154 users\hyperref[sec:hello]{(see Sec 3)}. Left: Are you satisfied with the StackOverflow newsletter? Right: Would you like customizable content recommendations from StackOverflow?}
\end{figure}

\textbf{\textit{"Search is what you do when you're looking for something. Discovery is when something wonderful that you didn't know existed, finds you."}}\\

- CNN Money, "The race to create a 'smart' Google\\

Recommendation systems have attracted considerable interest from both the academic and industrial research communities since their conception in the 1990's \cite{1,2,3}, and continue to represent an area of active research today.

The commercial value of recommendation engines has proven to be immense: for instance, 67\% of movies watched on Netflix\cite{4} are recommended. Amazon generates 35\%\cite{5} of it's total sales from recommendations to users, and Google News recommendations\cite{6} generate 38\% more clickthrough. 

This commercial success notwithstanding, there has been surprisingly little penetration of recommendation systems into more general areas of society, such as education. Despite the impetus provided by online tutoring platforms such as Coursera and Khan Academy, the problem of recommending temporally relevant instructional material in a truly customizable form remains academic\cite{7,8}.

Probably the closest existing systems are the academia.edu\cite{9} newsletter and the Mendeley\cite{10} suggestion system, which circulate most highly cited research papers within a chosen area(s) of interest to users. However, research papers correspond only to a minority of the larger education community, which remains an open opportunity for research and development in this area.

In this project, we extend the focus to the popular Question-and-Answer platform StackOverflow\cite{11}. StackOverflow features a large corpus of knowledge and content covering many areas of Computer Science and Software development in particular. Further, content on StackOverflow is inherently temporal, and thus presents users with the opportunity to stay updated with current trends in their areas of interest.

However, our survey \hyperref[sec:hello]{(see Sec 3)} revealed that existing StackOverflow tools present two obstacles to achieving this: firstly, no user customizable recommendation system exists for the platform. Secondly, the existing newsletter chooses content from all areas on the website, and hence only a very small subset of it is relevant to a given user. 

We therefore propose in this work to develop a personalizable content recommendation system for StackOverflow users. The remainder of this paper is organised as follows. Firstly, our introduction concludes with a formal description of our user group, it's software tool, it's goal and the intervening problem. \hyperref[lit]{Section 2} details our literature study. In \hyperref[sec:hello]{Section 3}, we present the results of our user survey. \hyperref[start]{Section 4} presents a brief discussion of our start up exercise statement. Finally, we conclude the paper.


\subsection{Formal Definition}
%explain P U T G

\subsubsection{Problem}
\label{this}
\begin{itemize}

\item StackExchange offers a rudimentary newsletter. It includes top weekly questions and new unanswered questions.\footnote{The newsletter does provide an option to follow a specific topic over a brief period (3-8 hours).However, all content corresponding to the given topic is presented and the request must be resubmitted every 8 hours.} 

\item The service is common to all users and cannot be customized according to specific user preference.

\item This makes it difficult for users to receive content relevant to them, and thus stay up-to-date with the latest developments in their specific areas of interest.

\end{itemize}
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{snip}
\caption{72\% of StackOverflow users report that it helps with their job. 66\% use it as a resource for learning.}
\end{figure}
\subsubsection{User Group}

32 million users visit Stack Overflow every month\cite{12}. From the StackOverflow developer survey\cite{12}, 66\% of respondents reported that they use StackOverflow to learn and keep abreast of developments in their areas of interest. Also, 63\% of respondents report that they visit StackOverflow multiple times a day. \\

76\% of the users from our survey wanted to hear from StackOverflow. Of these, 67\% of respondents \hyperref[sec:hello]{(see Sec 3)} report dissatisfaction with the existing StackOverflow newsletter and nearly as large a percentage (63\%) report that they would like customizable content recommendations. These represent our user group. 

\subsubsection{Software Tool}

The tool in question is StackOverflow, a sub site of StackExchange meant for programming and software engineering related QnA. It is a community moderated platform created by Jeff Atwood and Joel Spolsky in 2008. One can ask questions, answer questions, upvote questions or answers, reply to answers for specific queries among other things. Users of StackOverflow earn reputation points and badges if the community deems their contributions valuable in the form of upvotes. All content is licensed under the Creative Commons Attribute-ShareAlike license.

Stack Overflow is written in C\# using the ASP.NET MVC (Model-View-Controller) framework, and Microsoft SQL Server for the database and the Dapper object-relational mapper used for data access. To build a customizable system for this platform, we will create a website scraper to pick up data. We will then categorize it according to various parameters including tags, timestamps, upvote count etc.

\subsubsection{Goal}

Our user group's goal is to stay updated with the latest news and developments in their stated areas of interest. Note that this goal is inherently user specific, and therefore cannot be accomplished simply by reading the StackOverflow newsletter\hyperref[this]{(see Sec 1.1.1)}. It is also pertinent to point out that a search based on tags, such as 'python' (526584 results) or 'prefix trees' (20083 results) would yield large masses of content, unfiltered by popularity, relevance, or temporality.

\subsection{The Gulf of Evaluation}
While \hyperref[this]{Section 1.1} defines our problem in a software engineering sense, the question of how to arrive at a quantitative evaluation of our proposed system remains to be addressed.

Our stated problem is defined on two key counts:(i) personalize to a specific user (ii) keeping "up to date" with latest developments in a stated area. Arriving at a quantitative evaluation of such a system is less straightforward than, say, evaluating a modification to a text editor environment, in which case simply measuring average user error rate with and without the modification would suffice. We will carry out the following assessments to address this gulf:

\subsubsection{User Satisfaction Survey}
Similar in spirit to the survey we conducted to define our problem, we will carry out a user survey of our system in the final two to three weeks of the semester. Users will input stated areas of interest and report their levels of satisfaction with the system versus the StackOverflow newsletter. While we will not have a ground truth to measure against in this case, we remain hopeful that the survey will still provide value to our evaluation.

\subsubsection{Sanity Checks}
We will manually identify ground truth content in specific areas (for instance, fixes to a well known bug in Python), and examine whether such content is recommended by our system.

\subsubsection{Statistical p value testing}
As part of our user survey, we will ask participants to identify the number of articles from our system that they found relevant and useful, over and above the StackOverflow newsletter. This measure will serve as an (approximate) Gaussian distribution from which we will calculate a p value to evaluate the statistical probability that our system has a positive effect.
\section{Literature Study}

\subsection{Methodology}
\label{lit}
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{c}
\caption{Our initial search terms. Size depicts number of results.}
\end{figure}

\begin{figure*}[!h]
\centering
\includegraphics[width=\textwidth]{Collective}
\caption{Sample statistics from our \hyperref[sec:hello]{user survey}.}
\end{figure*}
Our search was primarily conducted on Google Scholar, since it is a library that includes publications from most organisations such as IEEE, ACM, and so on. We initially conducted a search for the keywords listed in Fig. 3, which visualizes each according to the number of results it returned on Google Scholar. The initial search unsurprisingly returned an intractably large number of articles in each category; for instance, 380000 results for content filtering, 250000 results for recommendation systems, and so on. 

Our initial preprocessing strategy was simple: we argue that any article relevant to our particular problem must contain ALL the essential terms that define the problem. Our initial attempt at pruning the result set was thus defined by the following search:\\ \textbf{recommendation OR ranking AND filtering AND temporal data}.

This search pruned our result space to a cardinality of approximately 27000 articles. Then, we utilized the fact that the first recommendation systems began to appear in the mid to late 90's, which refined our search to the period between 1995 and the present (2016). This further scoped our results to a cardinality of 18000 Google Scholar entries.

To motivate our next search filter, we introduce a generic binary classification of recommendation systems according to their differing reliance on training data: collaborative versus content based filtering systems\cite{13}. Collaborative filtering methods are based on collecting and analyzing a large amount of information on users$â€™$ behaviors, activities or preferences and predicting what users will like based on their similarity to other users.

While we do not dispute that collaborative approaches in general yield consistently good results, we do not seek to implement such an approach in our project for the following reason: Collaborative approaches rely on the availability of large corpuses of user data and preferences, which are usually generated over years of recorded data. The constraints imposed by utilization of simple user surveys make it impossible for us to generate such a corpus within the time constraints of a semester project. 

Instead, we adopt a content based filtering approach\cite{13}, which are based on a description of the item and a profile of the user$'$s preference.[28] In a content-based recommender system, keywords are used to describe the items and a user profile is built to indicate the type of item this user likes. In other words, these algorithms try to recommend items that are similar to those that a user liked in the past (or is examining in the present). In particular, various candidate items are compared with items previously rated by the user and the best-matching items are recommended. Such an approach fits well into the data provided by a user survey, into which users may enter specific areas of interest based on which our system can recommend content.

Thence, we now restrict our search to content based filtering systems, while continuing to incorporate the search parameters described earlier. This now prunes our search space to a cardinality of 700 articles.

We now proceed to manually select individual articles. Our selection criteria are as follows. We firstly look for relevance to our proposed problem, disqualifying articles that are clearly unrelated or address irrelevant research questions not connected to our chosen problem. 

Then, we apply a simple heuristic filter for the number of citations. We exclude any article cited less than 20 times, excepting those articles that appeared after 2014. Our literature survey hence \textbf{maintains a H index of 18}.

It is pertinent to point out here that our filtered search does identify well known research in the field\cite{14,17}.

\subsection{Summary of selected papers}
We now summarise the content of our chosen subset of literature, and point out the salient contribution and relevance of each article for our specific application. We begin with reference\cite{14}, a seminal survey paper in the area of recommender systems. The article presents a general taxonomy for recommendation systems, which informed our search. Within the taxonomy, we identify our system as a Keyword based Item to User correlation technique, that outputs predictions featuring a persistent level of user personalization.

In 2009, Chu and Park\cite{15}, proposed a predictive bi-linear model that evaluates content using a combination of user profile, feature responses of content, and timestamp.While the technique presented in the paper is primarily a collaborative one and therefore beyond our ability to reproduce \hyperref[lit]{(see Sec 2.1)}, the paper remains an important one to point out the role of temporality in determining user preference. 

This tradition is again observable in\cite{16}, which introduces a personalised context aware system for TV content recommendation. The system proved to have industrial success after being commercialized, underlining the relevance of user customized recommendation.

Reference\cite{17} presents a comprehensive survey of the state of the art in the recommender systems of 2012. It is interesting to contrast the contributions of this survey with the original one conducted in 2001. The primary additions to traditional recommendation systems take two forms: firstly, social context is used to enhance recommendation results in a manner similar to that described in\cite{16}. Secondly, and more importantly from the point of view of our project, the 2012 survey article stresses the importance of user personalization in the form of highly sophisticated and frequently updated user models.

\cite{18} presents a study of the impact of various factors on the commercial success of a recommendation system. The study found that the participant was a significant factor in determining persuasiveness, and that there should be more factors related to the participants that could affect the recommendation persuasiveness. The article received 233 citations in a ten year period, which serves as an additional confirmation of the importance of user personalization.

Chicaiza et al\cite{19} developed an education specific taxonomy of user profiles to aid in the personalization profiles for educational recommendation systems. While the established classification corresponds to the collaborative paradigm \hyperref[lit]{(see Sec 2.1)} would take too long for us to implement, the paper does serve to motivate our approach to personalization.

Reference\cite{20} presents a user adaptive music recommendation system that takes into account changing user interests with time. While this approach is again difficult to replicate, it serves as a motivator for adaptivity to temporal user interests.

In addition to these, we briefly discuss additional relevant work in the \hyperref[intro]{introduction} section, and do not repeat those here.



\section{User Survey}
\label{sec:hello}

% Before starting off with the project we wanted to analyze user sentiments about stackoverflow.com. This includes the type of users from various age groups, what they would most likely use stackoverflow.com for, what are their usage trends and what do they look up stackoverflow.com. These were some of the questions, responses to which which helped us in identifying the user needs and based on the survey result of which we will be building upon our system. 

Our survey form is listed in \hyperref[app]{Appendix A}. We begin by collecting demographical information about the participant, such as age group and profession. 

We then solicit information about the participant's trends of usage on StackOverflow. Questions include the user's areas of interest, their frequency of use of the website, and what they use it for.

Having collected this generic information, we then proceed to more specific queries about our proposed area of work. We ask if the user is aware of the existing StackOverflow newsletter, and if so whether it keeps her adequately informed on topics of her interest. Finally, we ask if she would like a customized newsletter from the website, the parameters of which she may modify. 

\subsection {Results}

The survey was conducted on a user base of 150+ people. We estimate that users on average spent  $\approx$5 minutes to read the description, understand the purpose of the survey and answer the questions. We summarise the results below : 
\begin{itemize}


\item Students and professionals comprised $\approx$80\% of the participants. Only 11\% of our survey participants
were from academia. 

\item Almost 90\% of the respondents were in the age range 18-25 or 25-50. This reaffirms our initial observation that most users of the website are either students or professionals.

\item Our respondents listed many areas of interest including programming languages(Java, Python, C/C++), databases, networking, operating systems etc. took the survey. This indicates the diversity of areas that StackOverflow provides knowledge in, and the breadth of users who consider it a reliable source of information.
 
\item The respondents who used stackoverflow everyday or at least 2-3 time a week formed 77\% of the user base with everyday users comprising 37\%. This speaks to the credibility of our user pool, since the most frequent users of the website would be the best informed as to how StackOverflow's corpus of knowledge may be leveraged.
 
\item 80\% of our survey audience used stackoverflow for specific programming errors and 48\% use it to learn languages and algorithms. It is noteworthy that despite the proliferation of online tutoring portals such as Coursera and Khan Academy, almost half our respondents still utilize stackoverflow.com to learn new things. The fact that 80\% of respondents use StackOverflow for programming errors is overwhelming evidence that the platform is the best available choice for information on debugging in general.

\item 75\% of the respondents reported that they would like to hear from StackOverflow. This result reaffirms our motivation to provide a content recommendation system for the site.

\item 60\% of our user pool reported that they were dissatisfied with the existing StackOverflow newsletter. Indeed, 80\% wanted the newsletter to be customizable.

\item Our survey had a total of $\frac{154}{12}\approx13$ people hours.
\end{itemize}

% \subsection {Discussion}
% Based upon the user survey results it was pretty evident that a newsletter is needed for students and professionals alike. Something which is customizable and at the
% same time keeps you updated based on user preference is the need of the hour. This will serve the purpose of answering questions based on user needs. The survey
% also indicated that 54\% of the respondents were interested in frequently asked questions whereas 48\% were interested in ones with most votes. This survey lead us
% to concluding that user needed a system that will keep them updated with the most talked about questions in their field of interest.	 

\section {Statement of Start up exercise}
\label{start}
As described earlier \hyperref[this]{(see Sec 1.1)}, StackOverflow runs on C\# using the ASP.net MVC controller framework. All four members of our project team have a working knowledge of C\# and have used it previously. Our start up exercise involves \textbf{implementing a website scraper in C\#}. This corresponds to the logical first step in the development of our system. We will then use our scraper to create a representative dataset, which will serve as a test bench for our recommendation system. 
  
% %\begin{figure}
% %\centering
% %\includegraphics[height=1in, width=1in]{sampleop}
% \caption{A sample black and white graphic
% that has been resized with the \texttt{includegraphics} command.}
% \end{figure}
% \begin{table}
% \centering
% \caption{Frequency of Special Characters}
% \begin{tabular}{|c|c|l|} \hline
% Non-English or Math&Frequency&Comments\\ \hline
% \O & 1 in 1,000& For Swedish names\\ \hline
% $\pi$ & 1 in 5& Common in math\\ \hline
% \$ & 4 in 5 & Used in business\\ \hline
% $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
% \hline\end{tabular}
% \end{table}

\section{Conclusions}
Surveying a sample of our user group, the users of StackOverflow.com, we documented one of their goals of using the site as that of looking for current content in their area(s) of interest. We observed, given the existing tools of the website, problems of content relevance ranking and user customization. Motivated by our findings, we proposed a content based filtering system to recommend customized content to users based on their stated interests. 
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\appendix
%Appendix A
\section{Our Survey Form}
\label{app}
\begin{figure*}[!h]
\centering
\includegraphics[width=\textwidth]{survey1}
%\caption{}
\end{figure*}
\begin{figure*}[!h]
\centering
\includegraphics[width=\textwidth]{survey2}
%\caption{}
\end{figure*}
% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy
%\balancecolumns % GM June 2007
% That's all folks!
\end{document}
